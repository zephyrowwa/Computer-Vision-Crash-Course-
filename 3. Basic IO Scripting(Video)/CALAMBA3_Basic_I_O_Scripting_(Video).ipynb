{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 313\n",
        "Code Title: | CPE 313-CPE32S3 - Advanced Machine Learning and Deep Learning\n",
        "2nd Semester | AY 2024-2025\n",
        "<hr> | <hr>\n",
        "\n",
        "<u>**ACTIVITY NO.** | **TITLE**\n",
        "**Name** | Calamba, Liam Francis\n",
        "**Section** | CPE31S3\n",
        "**Date Performed**: | 2 21 25\n",
        "**Date Submitted**: | 2 21 25\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to introduce students to OpenCV's I/O Functionality for video processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Read and write video files using openCV.\n",
        "* Utilize openCV to capture and display images and videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGqUyBbHlhaP"
      },
      "source": [
        "**NOTE:** For this laboratory activity, it is recommended that you download and run the Python notebook on *Spyder IDE*. You must install dependencies by running `!pip install numpy` and `!pip install opencv-python==4.6.0.66`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a_P1hg9HSXL"
      },
      "source": [
        "### Reading/Writing a Video File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6iPo_ddHXh6"
      },
      "source": [
        "OpenCV provides the `VideoCapture` and `VideoWriter` classes that support various video file formats. The supported formats vary by system but should always include an AVI. Via its `read()` method, a `VideoCapture` class may be polled for new frames until it reaches the end of its video file. Each frame is an image in a BGR format.\n",
        "\n",
        "Conversely, an image may be passed to the `write()` method of the `VideoWriter` class, which appends the image to a file in VideoWriter. Let's look at an example that reads frames from one AVI file and writes them to another with a YUV encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "videoCapture = cv2.VideoCapture('MyInputVid.avi')\n",
        "\n",
        "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
        "size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "videoWriter = cv2.VideoWriter(\n",
        "    'MyOutputVid.avi', cv2.VideoWriter_fourcc('I', '4', '2', '0'),\n",
        "    fps, size)\n",
        "\n",
        "success, frame = videoCapture.read()\n",
        "while success: # Loop until there are no more frames\n",
        "  videoWriter.write(frame)\n",
        "  success, frame = videoCapture.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P6hYs7TJwNe"
      },
      "source": [
        "The arguments to the VideoWriter class constructor deserve special attention. A video's filename must be specified. Any preexisting file with this name is overwritten. A video codec must also be specified. The available codecs may vary from system to system. These are the options that are included:\n",
        "* `cv2.VideoWriter_fourcc('I','4','2','0')`: This option is an uncompressed YUV encoding, 4:2:0 chroma subsampled. This encoding is widely compatible but produces large files. The file extension should be .avi.\n",
        "* `cv2.VideoWriter_fourcc('P','I','M','1')`: This option is MPEG-1. The file extension should be .avi.\n",
        "* `cv2.VideoWriter_fourcc('X','V','I','D')`: This option is MPEG-4 and a preferred option if you want the resulting video size to be average. The file\n",
        "extension should be .avi.\n",
        "* `cv2.VideoWriter_fourcc('T','H','E','O')`: This option is Ogg Vorbis. The file extension should be .ogv.\n",
        "* `cv2.VideoWriter_fourcc('F','L','V','1')`: This option is a Flash video. The file extension should be .flv.\n",
        "\n",
        "A frame rate and frame size must be specified too. Since we are copying video frames from another video, these properties can be read from the get() method\n",
        "of the VideoCapture class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQOlAY8KGZm"
      },
      "source": [
        "### Capturing camera frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aex22DkKJG9"
      },
      "source": [
        "A stream of camera frames is represented by the VideoCapture class too. However, for a camera, we construct a VideoCapture class by passing the camera's device index instead of a video's filename. Let's consider an example that captures 10 seconds of video from a camera and writes it to an AVI file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wTDi4mPFK1ud"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "cameraCapture = cv2.VideoCapture(0)\n",
        "fps = 30 # an assumption\n",
        "\n",
        "size = (int(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(cameraCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "videoWriter = cv2.VideoWriter(\n",
        "    'MyOutputVid.avi', cv2.VideoWriter_fourcc('I', '4', '2', '0'),\n",
        "    fps, size)\n",
        "\n",
        "success, frame = cameraCapture.read()\n",
        "numFramesRemaining = 10 * fps - 1\n",
        "\n",
        "while success and numFramesRemaining > 0:\n",
        "  videoWriter.write(frame)\n",
        "  success, frame = cameraCapture.read()\n",
        "  numFramesRemaining -= 1\n",
        "\n",
        "cameraCapture.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm43aVOVL8Sr"
      },
      "source": [
        "Unfortunately, the `get()` method of a VideoCapture class does not return an accurate value for the camera's frame rate; it always returns 0. The official\n",
        "documentation at http://docs.opencv.org/modules/highgui/doc/reading_ and_writing_images_and_video.html reads:\n",
        "\n",
        "> \"When querying a property that is not supported by the backend used by the VideoCapture class, value 0 is returned.\"\n",
        "\n",
        "This occurs most commonly on systems where the driver only supports basic functionalities. For the purpose of creating an appropriate VideoWriter class for the camera, we have to either make an assumption about the frame rate (as we did in the code previously) or measure it using a timer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWtfP2CdMh16"
      },
      "source": [
        "The `read()` method is inappropriate when we need to synchronize a set of cameras or a multihead camera (such as a stereo camera or Kinect). Then, we use the `grab()` and `retrieve()` methods instead. For a set of cameras, we use this code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X8pO75o0Mo9R"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nsuccess0 = cameraCapture0.grab()\\nsuccess1 = cameraCapture1.grab()\\nif success0 and success1:\\n  frame0 = cameraCapture0.retrieve()\\n  frame1 = cameraCapture1.retrieve()\\n\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "success0 = cameraCapture0.grab()\n",
        "success1 = cameraCapture1.grab()\n",
        "if success0 and success1:\n",
        "  frame0 = cameraCapture0.retrieve()\n",
        "  frame1 = cameraCapture1.retrieve()\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIFMXY7MuGB"
      },
      "source": [
        "### Displaying images in a window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxLV090lMwPQ"
      },
      "source": [
        "One of the most basic operations in OpenCV is displaying an image. This can be done with the imshow() function. If you come from any other GUI framework\n",
        "background, you would think it sufficient to call imshow() to display an image. This is only partially true: the image will be displayed, and will disappear immediately. This is by design, to enable the constant refreshing of a window frame when working\n",
        "with videos. Here's a very simple example code to display an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t-AQAy_eMzp5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('myimag.jpg')\n",
        "cv2.imshow('my img', img)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4GMdJObM9VQ"
      },
      "source": [
        "The `imshow()` function takes two parameters: the name of the frame in which we want to display the image, and the image itself. We'll talk about `waitKey()` in more detail when we explore the displaying of frames in a window.\n",
        "\n",
        "The aptly named `destroyAllWindows()` function disposes of all the windows created by OpenCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuMkv4fKNGoo"
      },
      "source": [
        "### Displaying camera frames in a window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1_PeWA1NJ7x"
      },
      "source": [
        "OpenCV allows named windows to be created, redrawn, and destroyed using the `namedWindow()`, `imshow()`, and `destroyWindow()` functions. Also, any window may capture keyboard input via the `waitKey()` function and mouse input via the `setMouseCallback()` function. Let's look at an example where we show the frames of a live camera input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OrBPLsvBNQLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Showing camera feed. Click window or press any key to stop.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "clicked = False\n",
        "\n",
        "def onMouse(event, x, y, flags, param):\n",
        "  global clicked\n",
        "  if event == cv2.EVENT_LBUTTONUP:\n",
        "    clicked = True\n",
        "\n",
        "cameraCapture = cv2.VideoCapture(0)\n",
        "cv2.namedWindow('MyWindow')\n",
        "cv2.setMouseCallback('MyWindow', onMouse)\n",
        "\n",
        "print('Showing camera feed. Click window or press any key to stop.')\n",
        "\n",
        "success, frame = cameraCapture.read()\n",
        "\n",
        "while success and cv2.waitKey(1) == -1 and not clicked:\n",
        "  cv2.imshow('MyWindow', frame)\n",
        "  success, frame = cameraCapture.read()\n",
        "\n",
        "cv2.destroyWindow('MyWindow')\n",
        "cameraCapture.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sbqf0tMOE0_"
      },
      "source": [
        "The argument for `waitKey()` is a number of milliseconds to wait for keyboard input. The return value is either `-1` (meaning that no key has been pressed) or an ASCII keycode, such as `27` for Esc. For a list of ASCII keycodes, see http://www.asciitable.com/. Also, note that Python provides a standard function, `ord()`, which can convert a character to its ASCII keycode. For example, `ord('a')` returns `97`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpZ3cXeaPKxF"
      },
      "source": [
        "OpenCV's window functions and `waitKey()` are interdependent. OpenCV windows are only updated when `waitKey()` is called, and `waitKey()` only captures input when an OpenCV window has focus.\n",
        "\n",
        "The mouse callback passed to `setMouseCallback()` should take five arguments, as seen in our code sample. The callback's param argument is set as an optional third argument to `setMouseCallback()`. By default, it is 0. The callback's event argument is one of the following actions:\n",
        "\n",
        "* `cv2.EVENT_MOUSEMOVE`: This event refers to mouse movement\n",
        "* `cv2.EVENT_LBUTTONDOWN`: This event refers to the left button down\n",
        "* `cv2.EVENT_RBUTTONDOWN`: This refers to the right button down\n",
        "* `cv2.EVENT_MBUTTONDOWN`: This refers to the middle button down\n",
        "* `cv2.EVENT_LBUTTONUP`: This refers to the left button up\n",
        "* `cv2.EVENT_RBUTTONUP`: This event refers to the right button up\n",
        "* `cv2.EVENT_MBUTTONUP`: This event refers to the middle button up\n",
        "* `cv2.EVENT_LBUTTONDBLCLK`: This event refers to the left button being double-clicked\n",
        "* `cv2.EVENT_RBUTTONDBLCLK`: This refers to the right button being double-clicked\n",
        "* `cv2.EVENT_MBUTTONDBLCLK`: This refers to the middle button being double-clicked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mac_puc9PpFM"
      },
      "source": [
        "The mouse callback's flags argument may be some bitwise combination of the following events:\n",
        "\n",
        "* `cv2.EVENT_FLAG_LBUTTON`: This event refers to the left button being pressed\n",
        "* `cv2.EVENT_FLAG_RBUTTON`: This event refers to the right button being pressed\n",
        "* `cv2.EVENT_FLAG_MBUTTON`: This event refers to the middle button being pressed\n",
        "* `cv2.EVENT_FLAG_CTRLKEY`: This event refers to the Ctrl key being pressed\n",
        "* `cv2.EVENT_FLAG_SHIFTKEY`: This event refers to the Shift key being pressed\n",
        "* `cv2.EVENT_FLAG_ALTKEY`: This event refers to the Alt key being pressed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ox0ewgrPlCM"
      },
      "source": [
        "Unfortunately, OpenCV does not provide any means of handling window events. For example, we cannot stop our application when a window's close button is\n",
        "clicked. Due to OpenCV's limited event handling and GUI capabilities, many developers prefer to integrate it with other application frameworks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbaLZ7KTQIfT"
      },
      "source": [
        "Perform each of the following tasks.\n",
        "\n",
        "1. Try reading and writing a video file in various formats.\n",
        "2. Similar to activity #1, show an image of your favorite character on a window. Afterwards, slice so that only the character's face is displayed.\n",
        "3. Capture video from your webcam and display on a window. Afterwards, the video should be written as a new file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "1) reading and writing video files in various formats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "videoCapture = cv2.VideoCapture('brodie hold on.mp4')\n",
        "\n",
        "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
        "size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "videoWriter = cv2.VideoWriter(\n",
        "    'supact1vidcap.avi', cv2.VideoWriter_fourcc('X','V','I','D'),\n",
        "    fps, size)\n",
        "\n",
        "success, frame = videoCapture.read()\n",
        "print(success)\n",
        "while success: # Loop until there are no more frames\n",
        "  videoWriter.write(frame)\n",
        "  success, frame = videoCapture.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2) show an image of your favorite character on a window. Afterwards, slice so that only the character's face is displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "crop = cv2.imread('supactchar.jpg')\n",
        "helm = crop[0:450, 300:700]\n",
        "cv2.imshow('cropp', helm)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3) Capture video from your webcam and display on a window. Afterwards, the video should be written as a new file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vid capture: True\n"
          ]
        }
      ],
      "source": [
        "clicked = False\n",
        "\n",
        "def onMousesupple(event, x, y, flags, param):\n",
        "  global clicked\n",
        "  if event == cv2.EVENT_MBUTTONDOWN:\n",
        "    clicked = True\n",
        "\n",
        "cameraCapture = cv2.VideoCapture(0)\n",
        "cv2.namedWindow('supact')\n",
        "cv2.setMouseCallback('supact', onMousesupple)\n",
        "fps = 60 # an assumption\n",
        "\n",
        "size = (int(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        int(cameraCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "videoWriter = cv2.VideoWriter(\n",
        "    'supactwebcamcliccstop.avi', cv2.VideoWriter_fourcc('I', '4', '2', '0'),\n",
        "    fps, size)\n",
        "\n",
        "success, frame = cameraCapture.read()\n",
        "\n",
        "print('vid capture:', success)\n",
        "\n",
        "\n",
        "while success and cv2.waitKey(1) == -1 and not clicked: # showing and recording the webcam\n",
        "  # recording will stop if stop button is pressed\n",
        "  videoWriter.write(frame)\n",
        "  cv2.imshow('supact', frame)\n",
        "  success, frame = cameraCapture.read()\n",
        "\n",
        "cv2.destroyWindow('supact')\n",
        "cameraCapture.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this activity I have now learned how to integrate my camera or any video capturing device, like how I created a new video but with another file extension by video recording (reading) a video, and also using my camera to record a video, also I learned about integrating my inputs like clicks and keypresses to do an action, there is a small hint of GUI, in this activity I used a key press to stop the recording and save it.\n",
        "\n",
        "I can see a new vision after this, there's a lot of ways I can use this fundamental to my future works, maybe a project that involves the use of realtime machine vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0a_P1hg9HSXL",
        "_YQOlAY8KGZm",
        "1RIFMXY7MuGB",
        "XuMkv4fKNGoo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
