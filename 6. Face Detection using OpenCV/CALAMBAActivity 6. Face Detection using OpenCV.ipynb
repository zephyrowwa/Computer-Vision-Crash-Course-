{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 313\n",
        "Code Title: | CPE 313-CPE32S3 - Advanced Machine Learning and Deep Learning\n",
        "2nd Semester | AY 2024-2025\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.** | **TITLE**\n",
        "**Name** | Calamba, Liam Francis\n",
        "**Section** | CPE31S3\n",
        "**Date Performed**: | 2 21 25\n",
        "**Date Submitted**: | 2 21 25\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to allow students to perform face detection on still images and videos using Haar cascades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKV8vexMpBJS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Utilize OpenCV to detect faces in still images and videos.\n",
        "* Demonstrate the use of Haar-like features for detection of other human features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NzR4JDbiyDg"
      },
      "source": [
        "Contrary to initial assumptions, conducting face detection on a static image and a video stream shares a remarkable similarity. Essentially, the latter is merely a sequential rendition of the former: when detecting faces in videos, it essentially involves applying face detection to every individual frame obtained from the camera feed. Of course, video face detection introduces additional elements like tracking, which aren't relevant to static images. Nevertheless, it's valuable to recognize that the fundamental principles behind both processes remain consistent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1gC-lR2izhw"
      },
      "source": [
        "### Performing face detection on still image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMLyshf2izdI"
      },
      "source": [
        "The first and most basic way to perform face detection is to load an image and detect faces in it. To make the result visually meaningful, we will draw rectangles around faces on the original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkwbbeEAoPlw"
      },
      "source": [
        "**Before implementing the code below**, check the contents of the `cv2.CascadeClassifier()` function. Provide an explanation of the function, its parameters before running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "# Make sure that for this activity, you have downloaded the\n",
        "# file indicated below from the resource linked in the instructional materials\n",
        "# in the module.\n",
        "\n",
        "import cv2\n",
        "\n",
        "picPath = (r'C:/Users/ZPHRRWA/Desktop/6. Face Detection using OpenCV/breaking_bad.jpg')\n",
        "haarPath = (r'C:/Users/ZPHRRWA/Desktop/6. Face Detection using OpenCV/haarcascade_frontalface_default.xml')\n",
        "\n",
        "def faceDetect(picPath):\n",
        "  face_cascade = cv2.CascadeClassifier(haarPath)\n",
        "\n",
        "  img = cv2.imread(picPath)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "\n",
        "  for (x, y, w, h) in faces:\n",
        "    img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 2)\n",
        "\n",
        "  cv2.imshow('unggabungga',img)\n",
        "  cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "iMDiBHDHn0qw",
        "outputId": "529a3dbd-2533-4c3d-dac0-29d00131c115"
      },
      "outputs": [],
      "source": [
        "faceDetect(picPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QKfV7ANos6O"
      },
      "source": [
        "**Analysis**:\n",
        "- Based on your earlier analysis, where do you think the face detection works in the line of code above?\n",
        "- Provide an analysis of the parameters of the `detectMultiScale` method.\n",
        "- Change the color of the border of the detected faces to red.\n",
        "- Are you able to make the borders thicker? Demonstrate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yap3yT5PsO8Q"
      },
      "source": [
        "### Performing face detection on video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbxG6gBphzF"
      },
      "source": [
        "**Step 1**: Create a file called face_detection.py and include the following codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBVolHTcGoCo"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WboZyA6lpk81"
      },
      "source": [
        "**Step 2:** After this, we declare a method, `detect()`, which will perform face detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHorhmfopnvV"
      },
      "outputs": [],
      "source": [
        "def detect():\n",
        "  face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "  eye_cascade = cv2.CascadeClassifier('/content/haarcascade_eye.xml')\n",
        "  camera = cv2.VideoCapture(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W4p9q1OqYP0"
      },
      "source": [
        "**Step 3:** The first thing we need to do inside the detect() method is to load the Haar cascade files so that OpenCV can operate face detection. As we copied\n",
        "the cascade files in the local `cascades/` folder, we can use a relative path. Then, we open a VideoCapture object (the camera feed). The VideoCapture  constructor takes a parameter, which indicates the camera to be used; zero indicates the first camera available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vVGMXB7rjPT"
      },
      "outputs": [],
      "source": [
        "  while (True):\n",
        "    ret, frame = camera.read()\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zieVeRN_rlxa"
      },
      "source": [
        "**Step 4:** Next up, we capture a frame. The read() method returns two values: a Boolean indicating the success of the frame read operation, and the frame\n",
        "itself. We capture the frame, and then we convert it to grayscale. This is a necessary operation, because face detection in OpenCV happens in the grayscale color space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_LBk8P-r36S"
      },
      "outputs": [],
      "source": [
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3VPUQRr7ii"
      },
      "source": [
        "**Step 5:** Much like the single still image example, we call detectMultiScale on the grayscale version of the frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELwHm8NqsAIp"
      },
      "outputs": [],
      "source": [
        "  for (x,y,w,h) in faces:\n",
        "    img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray, 1.03,\n",
        "    5, 0, (40,40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MA68hKlse7I"
      },
      "source": [
        "**Step 6:** Here we have a further step compared to the still image example: we create a region of interest corresponding to the face rectangle, and within this rectangle, we operate \"eye detection\". This makes sense as you wouldn't want to go looking for eyes outside a face (well, for human beings at least!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9V5PPcfsjpX"
      },
      "outputs": [],
      "source": [
        "  for (ex,ey,ew,eh) in eyes:\n",
        "    cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),\n",
        "    (0,255,0),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqjveHPspQ3"
      },
      "source": [
        "**Step 7:** Again, we loop through the resulting eye tuples and draw green rectangles around them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJlmIIERso0w"
      },
      "outputs": [],
      "source": [
        "\n",
        "    cv2.imshow(\"camera\", frame)\n",
        "    if cv2.waitKey(1000 / 12) & 0xff == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "detect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI59-kERsyxP"
      },
      "source": [
        "**Provide the following**:\n",
        "- Screenshot of the output for the working code once you've put it all together.\n",
        "- Summary of the steps you've performed along with observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "image output in the directory (idk how to put images in VS Code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1) get all the needed cascades from github\n",
        "2) understand the code\n",
        "3) copy the given code\n",
        "4) troubleshoot\n",
        "5) testing\n",
        "6) fine tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjTzJoxpT-N"
      },
      "source": [
        "In your Cameo project, include real-time face detection using Haar cascade. Show screenshots of the working demonstration for this supplementary activity.\n",
        "\n",
        "Additionally, implement similar steps to detect a smile using Haar cascades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "- this activity has a lot of troubleshooting and fixing because there was a lot of files that I needed to find on the internet, but I still got it. I am introduced to face detection in this activity by utilizing haar cascades, it detected my face while using my camera. I can now see how this can be combined with deep learning to be used in a lot of projects, it is also kind of open source and readily available wich is nice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ElMxAUPJGYLw",
        "X-RNZovNGV9k",
        "Mkyd0KjtGl79",
        "KQspxP0IGoO1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
